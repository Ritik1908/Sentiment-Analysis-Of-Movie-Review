{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis:\n",
    "\n",
    "Naive Bayez works great on textual data.\n",
    "\n",
    "### Work Flow:\n",
    "\n",
    "1. Text Preprocessing: Remove Html tags, common words, remove special characeters.\n",
    "2. Vectorize(BOW) the data.\n",
    "3. Pass data to algorithm and train.\n",
    "4. Deployement.\n",
    "\n",
    "\n",
    "\n",
    "## Bag Of Words:\n",
    "\n",
    "Find all unique words. For example we have following 4 words:-\n",
    "\n",
    "Each new row represent a review and it value contains occurennce of that word in a review.\n",
    "\n",
    "<table>\n",
    "\n",
    "<tr>\n",
    "<td>Great</td>\n",
    "<td>awesome</td>\n",
    "<td>poor</td>\n",
    "<td>pathetic</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>3</td>\n",
    "<td>1</td>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>0</td>\n",
    "<td>1</td>\n",
    "<td>2</td>\n",
    "<td>4</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "</table>\n",
    "\n",
    "\n",
    "Shape will become (50000, 4)\n",
    "\n",
    "50000 -> Number of reviews\n",
    "\n",
    "4 -> Number of unique words\n",
    "\n",
    "## Apply bayes theorem now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re\n",
    "import nltk # For StopWords\n",
    "from nltk.corpus import stopwords # For Stopwords\n",
    "from nltk.stem.porter import PorterStemmer # For stemming words\n",
    "from sklearn.feature_extraction.text import CountVectorizer # For Vectorizing words\n",
    "from sklearn.model_selection import train_test_split # For test train split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Dataset/IMDB Dataset.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sample(50000).reset_index()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IF ANYONE IS INTERESTED IN OBTAINING A COPY OF THIS FILM PLEASE READ THE BOTTOM OF THIS DESCRIPTION: First telecast by CBS on November 30, 2003, the made-for-TV Finding John Christmas is a sequel to the previous year\\'s A Town Without Christmas, with Peter Falk reprising his role as versatile guardian angel Max. Valerie Bertinelli plays Kathleen McAllister, a divorced small-town nurse whose depression... over the fact that the hospital ER she maintains may be forced to shut down because of a $100,000 debt is briefly lifted when she spots a newspaper picture taken by photojournalist Noah Greeley (David Cubitt). The picture shows an act of bravery performed by Noah\\'s firefighter brother Hank (William Russ), who mysteriously left town 25 years ago and hasn\\'t been seen since. Hank would like to quietly slip back into town without explanation or fanfare, but this proves impossible when Noah\\'s newspaper posts a $50,000 reward to identify Hank, known only to the public as \"John Christmas.\" And there\\'s something, very, very curious about that photo: It also shows a Santa Claus suit seemingly floating in midair without an occupant. That elusive \"Santa\" is of course the angelic Max, who pops up now and again throughout the story in a variety of guises to solve problems, dispense advice, tie up loose plot strands--and even share a musical duet with Kathleen\\'s talented daughter Socorro (Jennifer Pisana).<br /><br />INTERESTED IN HAVING A COPY: WRITE TO ME HERE: IAMASEAL2@YAHOO.COM'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One Review\n",
    "data['review'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning:\n",
    "\n",
    "1. Remove HTML Tags.\n",
    "2. Remove special characters.\n",
    "3. Convert everything to lower case.\n",
    "4. Removing Stop Words.\n",
    "5. Stemming (One words used in multiple form, example play, playing, played, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   index      50000 non-null  int64 \n",
      " 1   review     50000 non-null  object\n",
      " 2   sentiment  50000 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# No missing value in data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing Postive Negative to 0 and 1.\n",
    "data['sentiment'].replace({'positive': 1, 'negative': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25671</td>\n",
       "      <td>IF ANYONE IS INTERESTED IN OBTAINING A COPY OF...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14406</td>\n",
       "      <td>Tug-3 is absolutely right. Although I am sure ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31152</td>\n",
       "      <td>I just saw this early this morning on the Fox ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35568</td>\n",
       "      <td>I just don't get it. Why call this a sequel to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32247</td>\n",
       "      <td>This film easily rivals the emotional strength...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                             review  sentiment\n",
       "0  25671  IF ANYONE IS INTERESTED IN OBTAINING A COPY OF...          1\n",
       "1  14406  Tug-3 is absolutely right. Although I am sure ...          0\n",
       "2  31152  I just saw this early this morning on the Fox ...          0\n",
       "3  35568  I just don't get it. Why call this a sequel to...          0\n",
       "4  32247  This film easily rivals the emotional strength...          1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing HTML Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I just saw this early this morning on the Fox channel quite by accident (my dog woke me up) - I had seen it years ago and thought I remembered it fairly well. As a kid, I had enjoyed it. But now? As another poster commented, several of the reels were out of order, and while it was disorienting at first, and bizarre, it seemed to fit the production - what was just awful became surreal and amusing. Musical numbers for what I think was the \"big\" fundraiser show(\"you\\'re in show business, I\\'m in show business, most of the kids are in show business, let\\'s put on a show\")come out of nowhere BEFORE all the talk about putting on a show, and then fade without applause to totally unrelated \"straight\" scenes. The leading man\\'s girlfriend shows up, spits out lines and lines of dialogue, then disappears. I was half awake, and loved every insane minute of it.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[2].review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I just saw this early this morning on the Fox channel quite by accident (my dog woke me up) - I had seen it years ago and thought I remembered it fairly well. As a kid, I had enjoyed it. But now? As another poster commented, several of the reels were out of order, and while it was disorienting at first, and bizarre, it seemed to fit the production - what was just awful became surreal and amusing. Musical numbers for what I think was the \"big\" fundraiser show(\"you\\'re in show business, I\\'m in show business, most of the kids are in show business, let\\'s put on a show\")come out of nowhere BEFORE all the talk about putting on a show, and then fade without applause to totally unrelated \"straight\" scenes. The leading man\\'s girlfriend shows up, spits out lines and lines of dialogue, then disappears. I was half awake, and loved every insane minute of it.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing all HTML Tags\n",
    "clean = re.compile('<.*?>')\n",
    "re.sub(clean, '', data.iloc[2]. review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean HTML Tags:\n",
    "def clean_html(text):\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(clean_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I just saw this early this morning on the Fox channel quite by accident (my dog woke me up) - I had seen it years ago and thought I remembered it fairly well. As a kid, I had enjoyed it. But now? As another poster commented, several of the reels were out of order, and while it was disorienting at first, and bizarre, it seemed to fit the production - what was just awful became surreal and amusing. Musical numbers for what I think was the \"big\" fundraiser show(\"you\\'re in show business, I\\'m in show business, most of the kids are in show business, let\\'s put on a show\")come out of nowhere BEFORE all the talk about putting on a show, and then fade without applause to totally unrelated \"straight\" scenes. The leading man\\'s girlfriend shows up, spits out lines and lines of dialogue, then disappears. I was half awake, and loved every insane minute of it.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[2].review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting everything to lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lower(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(convert_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25671</td>\n",
       "      <td>if anyone is interested in obtaining a copy of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14406</td>\n",
       "      <td>tug-3 is absolutely right. although i am sure ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31152</td>\n",
       "      <td>i just saw this early this morning on the fox ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35568</td>\n",
       "      <td>i just don't get it. why call this a sequel to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32247</td>\n",
       "      <td>this film easily rivals the emotional strength...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                             review  sentiment\n",
       "0  25671  if anyone is interested in obtaining a copy of...          1\n",
       "1  14406  tug-3 is absolutely right. although i am sure ...          0\n",
       "2  31152  i just saw this early this morning on the fox ...          0\n",
       "3  35568  i just don't get it. why call this a sequel to...          0\n",
       "4  32247  this film easily rivals the emotional strength...          1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special(text):\n",
    "    x = \"\"\n",
    "    \n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            x = x + i\n",
    "        else:\n",
    "            x = x + \" \"\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i just saw this early this morning on the fox channel quite by accident (my dog woke me up) - i had seen it years ago and thought i remembered it fairly well. as a kid, i had enjoyed it. but now? as another poster commented, several of the reels were out of order, and while it was disorienting at first, and bizarre, it seemed to fit the production - what was just awful became surreal and amusing. musical numbers for what i think was the \"big\" fundraiser show(\"you\\'re in show business, i\\'m in show business, most of the kids are in show business, let\\'s put on a show\")come out of nowhere before all the talk about putting on a show, and then fade without applause to totally unrelated \"straight\" scenes. the leading man\\'s girlfriend shows up, spits out lines and lines of dialogue, then disappears. i was half awake, and loved every insane minute of it.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[2].review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i just saw this early this morning on the fox channel quite by accident  my dog woke me up    i had seen it years ago and thought i remembered it fairly well  as a kid  i had enjoyed it  but now  as another poster commented  several of the reels were out of order  and while it was disorienting at first  and bizarre  it seemed to fit the production   what was just awful became surreal and amusing  musical numbers for what i think was the  big  fundraiser show  you re in show business  i m in show business  most of the kids are in show business  let s put on a show  come out of nowhere before all the talk about putting on a show  and then fade without applause to totally unrelated  straight  scenes  the leading man s girlfriend shows up  spits out lines and lines of dialogue  then disappears  i was half awake  and loved every insane minute of it '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_special(data.iloc[2].review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25671</td>\n",
       "      <td>if anyone is interested in obtaining a copy of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14406</td>\n",
       "      <td>tug 3 is absolutely right  although i am sure ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31152</td>\n",
       "      <td>i just saw this early this morning on the fox ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35568</td>\n",
       "      <td>i just don t get it  why call this a sequel to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32247</td>\n",
       "      <td>this film easily rivals the emotional strength...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                             review  sentiment\n",
       "0  25671  if anyone is interested in obtaining a copy of...          1\n",
       "1  14406  tug 3 is absolutely right  although i am sure ...          0\n",
       "2  31152  i just saw this early this morning on the fox ...          0\n",
       "3  35568  i just don t get it  why call this a sequel to...          0\n",
       "4  32247  this film easily rivals the emotional strength...          1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review'] = data['review'].apply(remove_special)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text): \n",
    "    x = []\n",
    "    for i in text.split():\n",
    "        if i not in stopwords.words('english'):\n",
    "            x.append(i)\n",
    "    y = x[:]\n",
    "    x.clear()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i just saw this early this morning on the fox channel quite by accident  my dog woke me up    i had seen it years ago and thought i remembered it fairly well  as a kid  i had enjoyed it  but now  as another poster commented  several of the reels were out of order  and while it was disorienting at first  and bizarre  it seemed to fit the production   what was just awful became surreal and amusing  musical numbers for what i think was the  big  fundraiser show  you re in show business  i m in show business  most of the kids are in show business  let s put on a show  come out of nowhere before all the talk about putting on a show  and then fade without applause to totally unrelated  straight  scenes  the leading man s girlfriend shows up  spits out lines and lines of dialogue  then disappears  i was half awake  and loved every insane minute of it '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[2].review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saw',\n",
       " 'early',\n",
       " 'morning',\n",
       " 'fox',\n",
       " 'channel',\n",
       " 'quite',\n",
       " 'accident',\n",
       " 'dog',\n",
       " 'woke',\n",
       " 'seen',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'thought',\n",
       " 'remembered',\n",
       " 'fairly',\n",
       " 'well',\n",
       " 'kid',\n",
       " 'enjoyed',\n",
       " 'another',\n",
       " 'poster',\n",
       " 'commented',\n",
       " 'several',\n",
       " 'reels',\n",
       " 'order',\n",
       " 'disorienting',\n",
       " 'first',\n",
       " 'bizarre',\n",
       " 'seemed',\n",
       " 'fit',\n",
       " 'production',\n",
       " 'awful',\n",
       " 'became',\n",
       " 'surreal',\n",
       " 'amusing',\n",
       " 'musical',\n",
       " 'numbers',\n",
       " 'think',\n",
       " 'big',\n",
       " 'fundraiser',\n",
       " 'show',\n",
       " 'show',\n",
       " 'business',\n",
       " 'show',\n",
       " 'business',\n",
       " 'kids',\n",
       " 'show',\n",
       " 'business',\n",
       " 'let',\n",
       " 'put',\n",
       " 'show',\n",
       " 'come',\n",
       " 'nowhere',\n",
       " 'talk',\n",
       " 'putting',\n",
       " 'show',\n",
       " 'fade',\n",
       " 'without',\n",
       " 'applause',\n",
       " 'totally',\n",
       " 'unrelated',\n",
       " 'straight',\n",
       " 'scenes',\n",
       " 'leading',\n",
       " 'man',\n",
       " 'girlfriend',\n",
       " 'shows',\n",
       " 'spits',\n",
       " 'lines',\n",
       " 'lines',\n",
       " 'dialogue',\n",
       " 'disappears',\n",
       " 'half',\n",
       " 'awake',\n",
       " 'loved',\n",
       " 'every',\n",
       " 'insane',\n",
       " 'minute']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(data.iloc[2].review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "def stem_words(text):\n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "    z = y[:]\n",
    "    y.clear()\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(stem_words)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join Back\n",
    "def join_back(list_input):\n",
    "    return \" \".join(list_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(join_back)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Preparations:\n",
    "\n",
    "To get all words used in review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_f = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "Gaussian: 0.7097\n",
      "\n",
      "100\n",
      "Multinomial: 0.7342\n",
      "\n",
      "200\n",
      "Gaussian: 0.7577\n",
      "\n",
      "200\n",
      "Multinomial: 0.7729\n",
      "\n",
      "300\n",
      "Gaussian: 0.7862\n",
      "\n",
      "300\n",
      "Multinomial: 0.8048\n",
      "\n",
      "400\n",
      "Multinomial: 0.8142\n",
      "\n",
      "500\n",
      "Multinomial: 0.83\n",
      "\n",
      "800\n",
      "Bernaulli: 0.8304\n",
      "\n",
      "900\n",
      "Bernaulli: 0.8325\n",
      "\n",
      "1000\n",
      "Multinomial: 0.8327\n",
      "\n",
      "1000\n",
      "Bernaulli: 0.8397\n",
      "\n",
      "1200\n",
      "Bernaulli: 0.8432\n",
      "\n",
      "1300\n",
      "Bernaulli: 0.8449\n",
      "\n",
      "1800\n",
      "Bernaulli: 0.8472\n",
      "\n",
      "2000\n",
      "Bernaulli: 0.8501\n",
      "\n",
      "2600\n",
      "Bernaulli: 0.8527\n",
      "\n",
      "4000\n",
      "Bernaulli: 0.8537\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(100, 10000, 100):\n",
    "    \n",
    "    cv= CountVectorizer(max_features=i)\n",
    "    \n",
    "    x = cv.fit_transform(data['review']).toarray()\n",
    "    y = data.iloc[:,-1].values\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
    "        \n",
    "    clf1 = GaussianNB()\n",
    "    clf2 = MultinomialNB()\n",
    "    clf3 = BernoulliNB()\n",
    "\n",
    "    clf1.fit(x_train, y_train)\n",
    "    clf2.fit(x_train, y_train)\n",
    "    clf3.fit(x_train, y_train)\n",
    "\n",
    "    y_pred1 = clf1.predict(x_test)\n",
    "    y_pred2 = clf2.predict(x_test)\n",
    "    y_pred3 = clf3.predict(x_test)\n",
    "\n",
    "    a_score1 = accuracy_score(y_test, y_pred1)\n",
    "    a_score2 = accuracy_score(y_test, y_pred2)\n",
    "    a_score3 = accuracy_score(y_test, y_pred3)\n",
    "\n",
    "    if(a_score1 > max_f):\n",
    "        print(i)\n",
    "        print(\"Gaussian:\", a_score1)\n",
    "        max_f = a_score1\n",
    "        print()\n",
    "\n",
    "    if(a_score2 > max_f):\n",
    "        print(i)\n",
    "        print(\"Multinomial:\", a_score2)\n",
    "        max_f = a_score2\n",
    "        print()\n",
    "\n",
    "    if(a_score3 > max_f):\n",
    "        print(i)\n",
    "        print(\"Bernaulli:\", a_score3)\n",
    "        max_f = a_score3\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv= CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cv.fit_transform(data['review']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 36394)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 36394)\n",
      "(8000,)\n",
      "(2000, 36394)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = GaussianNB()\n",
    "clf2 = MultinomialNB()\n",
    "clf3 = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(x_train, y_train)\n",
    "clf2.fit(x_train, y_train)\n",
    "clf3.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = clf1.predict(x_test)\n",
    "y_pred2 = clf2.predict(x_test)\n",
    "y_pred3 = clf3.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian: 0.6155\n"
     ]
    }
   ],
   "source": [
    "print(\"Gaussian:\", accuracy_score(y_test, y_pred1))\n",
    "print(\"Multinomial:\", accuracy_score(y_test, y_pred2))\n",
    "print(\"Bernaulli:\", accuracy_score(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(\"models/model\", 'rb'))\n",
    "# result = loaded_model.score(X_test, Y_test)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_text = pickle.load(open(\"models/words\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = load_text.transform([\"worst movie ever\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
